# -*- coding: utf-8 -*-
# -----------------------------------------------------------------------------
# Copyright (c) 2025 Gabriele Tiboni
# MSc Thesis — Computer Engineering, University of Padua (UniPD)
#
# Rights and licensing:
# - This source file is intended for academic/research dissemination as part of a
#   Master’s thesis project.
# - If this repository includes a LICENSE file, this file is distributed under
#   those terms. Otherwise, all rights are reserved by the author.
#
# Notes on originality:
# - This script performs standard CSV aggregation (pandas) over evaluation outputs
#   produced by this project (batch_inference_eval + FD comparison). This is an
#   idiomatic research data-processing pattern.
#
# Purpose and scope:
# - Summarize barrier-proximity sweeps for ALL ablation models by scanning the
#   evaluation CSVs generated by run_barrier_proximity_all_ablation.py.
#
# Expected filename convention:
#   <exp_name>_test_eval_uXYZ.csv   where XYZ is 010 / 015 / 020 (etc.)
#
# Required columns:
#   price_err, delta_err, vega_err
#
# Output:
#   results/summary_barrier_u_sweep_ablation.csv
# -----------------------------------------------------------------------------

from __future__ import annotations

import argparse
import re
from pathlib import Path

import pandas as pd


# Must match your ablation exp_name naming exactly.
ABLATION_16_EXP_NAMES = [
    # --- 8 base ---
    "fno_plain",
    "fno_pino_lam0",
    "fno_pino",
    "fno_pino_lam1",
    "afno_no_phys",
    "afno_phys_lam0",
    "afno_phys",
    "afno_phys_lam1",
    # --- 8 + PFTD ---
    "fno_plain_pftd",
    "fno_pino_lam0_pftd",
    "fno_pino_pftd",
    "fno_pino_lam1_pftd",
    "afno_no_phys_pftd",
    "afno_phys_lam0_pftd",
    "afno_phys_pftd",
    "afno_phys_lam1_pftd",
]

REQ_ERR_COLS = ["price_err", "delta_err", "vega_err"]


def parse_exp_and_u(filename: str) -> tuple[str | None, float | None]:
    """
    Parse exp_name and u from:
        <exp_name>_test_eval_u015.csv
    """
    exp_name = None
    u_val = None

    if "_test_eval_" in filename:
        exp_name = filename.split("_test_eval_")[0]

    m = re.search(r"u(\d{3})", filename)
    if m:
        u_val = int(m.group(1)) / 100.0

    return exp_name, u_val


def safe_mean(series: pd.Series) -> float:
    s = pd.to_numeric(series, errors="coerce").dropna()
    return float(s.mean()) if not s.empty else float("nan")


def safe_max(series: pd.Series) -> float:
    s = pd.to_numeric(series, errors="coerce").dropna()
    return float(s.max()) if not s.empty else float("nan")


def main():
    parser = argparse.ArgumentParser(
        description="Summarize barrier proximity u-sweep for all ablation models."
    )
    parser.add_argument(
        "--results_root",
        type=str,
        default="results",
        help="Directory containing eval CSVs (recursive scan).",
    )
    parser.add_argument(
        "--pattern",
        type=str,
        default="**/*test_eval_u*.csv",
        help="Glob pattern relative to results_root.",
    )
    parser.add_argument(
        "--output_csv",
        type=str,
        default="results/summary_barrier_u_sweep_ablation.csv",
        help="Where to write the summary CSV.",
    )
    args = parser.parse_args()

    results_root = Path(args.results_root)
    if not results_root.is_dir():
        raise FileNotFoundError(f"results_root not found: {results_root}")

    paths = sorted(results_root.glob(args.pattern))

    ablation_set = set(ABLATION_16_EXP_NAMES)

    rows = []
    processed = 0
    skipped = 0
    not_ablation = 0

    for p in paths:
        exp_name, u = parse_exp_and_u(p.name)

        if exp_name not in ablation_set:
            not_ablation += 1
            continue

        try:
            df = pd.read_csv(p)
        except Exception:
            skipped += 1
            continue

        if not all(c in df.columns for c in REQ_ERR_COLS):
            skipped += 1
            continue

        rows.append(
            {
                "exp_name": exp_name,
                "u": u,
                "file": p.name,
                "path": str(p.as_posix()),
                "n_rows": int(len(df)),
                "price_mae": safe_mean(df["price_err"]),
                "delta_mae": safe_mean(df["delta_err"]),
                "vega_mae": safe_mean(df["vega_err"]),
                "price_max": safe_max(df["price_err"]),
                "delta_max": safe_max(df["delta_err"]),
                "vega_max": safe_max(df["vega_err"]),
            }
        )
        processed += 1

    if not rows:
        print("No ablation eval CSVs found matching the pattern and naming convention.")
        print(f"Scanned: {len(paths)} | not_ablation: {not_ablation} | skipped: {skipped}")
        return

    out = pd.DataFrame(rows)

    # Clean sort for table readability
    out = out.sort_values(["exp_name", "u", "file"])

    out_path = Path(args.output_csv)
    out_path.parent.mkdir(parents=True, exist_ok=True)
    out.to_csv(out_path, index=False)

    print(out)
    print(f"\nSaved: {out_path}")
    print(f"Scanned: {len(paths)} | processed: {processed} | not_ablation: {not_ablation} | skipped: {skipped}")


if __name__ == "__main__":
    main()
